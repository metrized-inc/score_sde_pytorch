{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yang-song/score_sde_pytorch/blob/main/Score_SDE_demo_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBJappt3toqj"
      },
      "source": [
        "# Preparation\n",
        "\n",
        "1. `git clone https://github.com/yang-song/score_sde_pytorch.git`\n",
        "\n",
        "2. Install [required packages](https://github.com/yang-song/score_sde_pytorch/blob/main/requirements.txt)\n",
        "\n",
        "3. `cd` into folder `score_sde_pytorch`, launch a local jupyter server and connect to colab following [these instructions](https://research.google.com/colaboratory/local-runtimes.html)\n",
        "\n",
        "4. Download pre-trained [checkpoints](https://drive.google.com/drive/folders/1tFmF_uh57O6lx9ggtZT_5LdonVK2cV-e?usp=sharing) and save them in the `exp` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa9OIcJmUKmZ",
        "outputId": "8fde468b-2c95-4003-f0bd-20ddad5248e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\tensorflow_gan\\python\\estimator\\tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Autoload all modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import importlib\n",
        "import os\n",
        "import functools\n",
        "import itertools\n",
        "import torch\n",
        "from losses import get_optimizer\n",
        "from models.ema import ExponentialMovingAverage\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_gan as tfgan\n",
        "import tqdm\n",
        "import io\n",
        "import likelihood\n",
        "import controllable_generation\n",
        "from utils import restore_checkpoint\n",
        "sns.set(font_scale=2)\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "import models\n",
        "from models import utils as mutils\n",
        "from models import ncsnv2\n",
        "from models import ncsnpp\n",
        "from models import ddpm as ddpm_model\n",
        "from models import layerspp\n",
        "from models import layers\n",
        "from models import normalization\n",
        "import sampling\n",
        "from likelihood import get_likelihood_fn\n",
        "from sde_lib import VESDE, VPSDE, subVPSDE\n",
        "from sampling import (ReverseDiffusionPredictor, \n",
        "                      LangevinCorrector, \n",
        "                      EulerMaruyamaPredictor, \n",
        "                      AncestralSamplingPredictor, \n",
        "                      NoneCorrector, \n",
        "                      NonePredictor,\n",
        "                      AnnealedLangevinDynamics)\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "-reedYgCU79v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YESSIR\n"
          ]
        }
      ],
      "source": [
        "# @title Load the score-based model\n",
        "sde = 'VESDE' #@param ['VESDE', 'VPSDE', 'subVPSDE'] {\"type\": \"string\"}\n",
        "if sde.lower() == 'vesde':\n",
        "  from configs.ve import cifar10_ncsnpp_continuous as configs\n",
        "\n",
        "  print('YESSIR')\n",
        "  ckpt_filename = \"exp/ve/cifar10_ncsnpp_continuous/checkpoint_24.pth\"\n",
        "  config = configs.get_config()  \n",
        "  sde = VESDE(sigma_min=config.model.sigma_min, sigma_max=config.model.sigma_max, N=config.model.num_scales)\n",
        "  sampling_eps = 1e-5\n",
        "elif sde.lower() == 'vpsde':\n",
        "  from configs.vp import cifar10_ddpmpp_continuous as configs  \n",
        "  ckpt_filename = \"exp/vp/cifar10_ddpmpp_continuous/checkpoint_8.pth\"\n",
        "  config = configs.get_config()\n",
        "  sde = VPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
        "  sampling_eps = 1e-3\n",
        "elif sde.lower() == 'subvpsde':\n",
        "  from configs.subvp import cifar10_ddpmpp_continuous as configs\n",
        "  ckpt_filename = \"exp/subvp/cifar10_ddpmpp_continuous/checkpoint_26.pth\"\n",
        "  config = configs.get_config()\n",
        "  sde = subVPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
        "  sampling_eps = 1e-3\n",
        "\n",
        "batch_size = 32 #@param {\"type\":\"integer\"}\n",
        "config.training.batch_size = batch_size\n",
        "config.eval.batch_size = batch_size\n",
        "\n",
        "random_seed = 0 #@param {\"type\": \"integer\"}\n",
        "\n",
        "sigmas = mutils.get_sigmas(config)\n",
        "scaler = datasets.get_data_scaler(config)\n",
        "inverse_scaler = datasets.get_data_inverse_scaler(config)\n",
        "score_model = mutils.create_model(config)\n",
        "\n",
        "optimizer = get_optimizer(config, score_model.parameters())\n",
        "ema = ExponentialMovingAverage(score_model.parameters(),\n",
        "                               decay=config.model.ema_rate)\n",
        "state = dict(step=0, optimizer=optimizer,\n",
        "             model=score_model, ema=ema)\n",
        "\n",
        "state = restore_checkpoint(ckpt_filename, state, config.device)\n",
        "ema.copy_to(score_model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "G8ei2Xsfg6JQ"
      },
      "outputs": [],
      "source": [
        "#@title Visualization code\n",
        "\n",
        "def image_grid(x):\n",
        "  size = config.data.image_size\n",
        "  channels = config.data.num_channels\n",
        "  img = x.reshape(-1, size, size, channels)\n",
        "  w = int(np.sqrt(img.shape[0]))\n",
        "  img = img.reshape((w, w, size, size, channels)).transpose((0, 2, 1, 3, 4)).reshape((w * size, w * size, channels))\n",
        "  return img\n",
        "\n",
        "def show_samples(x):\n",
        "  x = x.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "  img = image_grid(x)\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hbBGjCMNUsp"
      },
      "source": [
        "# Predictor Corrector sampling\n",
        "\n",
        "\n",
        "Recommended settings:\n",
        "\n",
        " | dataset | SDE | predictor | corrector | snr | n_steps |\n",
        "|:----:|:----:|:----------:|:--------:|:---:|:----:|\n",
        "|CIFAR-10 | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.16| 1|\n",
        "|CIFAR-10 | VP | EulerMaruyamaPredictor | None | - | - |\n",
        "|CIFAR-10 | subVP| EulerMaruyamaPredictor | None | - | - |\n",
        "| LSUN/CelebA-HQ/FFHQ 256px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.075 | 1 |\n",
        "| FFHQ 1024px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.15| 1 |\n",
        "\n",
        "Check `probability_flow` to run PC sampling based on discretizing the probability flow ODE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "_X41BhiLqJvM",
        "outputId": "8a5b3b5f-93ad-4baf-d66f-0a648f935170"
      },
      "outputs": [],
      "source": [
        "#@title PC sampling\n",
        "img_size = config.data.image_size\n",
        "channels = config.data.num_channels\n",
        "shape = (batch_size, channels, img_size, img_size)\n",
        "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
        "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
        "snr = 0.16 #@param {\"type\": \"number\"}\n",
        "n_steps =  1#@param {\"type\": \"integer\"}\n",
        "probability_flow = False #@param {\"type\": \"boolean\"}\n",
        "sampling_fn = sampling.get_pc_sampler(sde, shape, predictor, corrector,\n",
        "                                      inverse_scaler, snr, n_steps=n_steps,\n",
        "                                      probability_flow=probability_flow,\n",
        "                                      continuous=config.training.continuous,\n",
        "                                      eps=sampling_eps, device=config.device)\n",
        "\n",
        "x, n = sampling_fn(score_model)\n",
        "show_samples(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AdiQdwN2aFA"
      },
      "source": [
        "# Probability flow ODE\n",
        "\n",
        "With black-box ODE solvers, we can produce samples, compute likelihoods, and obtain a uniquely identifiable encoding of any data point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "iLQDfFvHSIGn",
        "outputId": "f1888e8b-4e70-446d-d248-9f1c1b6a7916"
      },
      "outputs": [],
      "source": [
        " #@title ODE sampling\n",
        "\n",
        "shape = (batch_size, 3, 32, 32)\n",
        "sampling_fn = sampling.get_ode_sampler(sde,                                        \n",
        "                                       shape, \n",
        "                                       inverse_scaler,                                       \n",
        "                                       denoise=True, \n",
        "                                       eps=sampling_eps,\n",
        "                                       device=config.device)\n",
        "x, nfe = sampling_fn(score_model)\n",
        "show_samples(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "MsdcLnhu7s46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
            "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
            "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
            "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch: 0/312, average bpd: 3.7587814331054688, NFE: 260\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32me:\\Metrized\\score_sde_pytorch\\Score_SDE_demo_PyTorch.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Metrized/score_sde_pytorch/Score_SDE_demo_PyTorch.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(img)\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mto(config\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Metrized/score_sde_pytorch/Score_SDE_demo_PyTorch.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m img \u001b[39m=\u001b[39m scaler(img)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Metrized/score_sde_pytorch/Score_SDE_demo_PyTorch.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m bpd, z, nfe \u001b[39m=\u001b[39m likelihood_fn(score_model, img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Metrized/score_sde_pytorch/Score_SDE_demo_PyTorch.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m bpds\u001b[39m.\u001b[39mextend(bpd)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Metrized/score_sde_pytorch/Score_SDE_demo_PyTorch.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch: \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mlength\u001b[39m}\u001b[39;00m\u001b[39m, average bpd: \u001b[39m\u001b[39m{\u001b[39;00mtorch\u001b[39m.\u001b[39mtensor(bpds)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m, NFE: \u001b[39m\u001b[39m{\u001b[39;00mnfe\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32me:\\Metrized\\score_sde_pytorch\\likelihood.py:99\u001b[0m, in \u001b[0;36mget_likelihood_fn.<locals>.likelihood_fn\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m     96\u001b[0m   \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mconcatenate([drift, logp_grad], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     98\u001b[0m init \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([mutils\u001b[39m.\u001b[39mto_flattened_numpy(data), np\u001b[39m.\u001b[39mzeros((shape[\u001b[39m0\u001b[39m],))], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 99\u001b[0m solution \u001b[39m=\u001b[39m integrate\u001b[39m.\u001b[39;49msolve_ivp(ode_func, (eps, sde\u001b[39m.\u001b[39;49mT), init, rtol\u001b[39m=\u001b[39;49mrtol, atol\u001b[39m=\u001b[39;49matol, method\u001b[39m=\u001b[39;49mmethod)\n\u001b[0;32m    100\u001b[0m nfe \u001b[39m=\u001b[39m solution\u001b[39m.\u001b[39mnfev\n\u001b[0;32m    101\u001b[0m zp \u001b[39m=\u001b[39m solution\u001b[39m.\u001b[39my[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
            "File \u001b[1;32mc:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\integrate\\_ivp\\ivp.py:589\u001b[0m, in \u001b[0;36msolve_ivp\u001b[1;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)\u001b[0m\n\u001b[0;32m    587\u001b[0m status \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[39mwhile\u001b[39;00m status \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 589\u001b[0m     message \u001b[39m=\u001b[39m solver\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    591\u001b[0m     \u001b[39mif\u001b[39;00m solver\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfinished\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    592\u001b[0m         status \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[1;32mc:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\integrate\\_ivp\\base.py:181\u001b[0m, in \u001b[0;36mOdeSolver.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt\n\u001b[1;32m--> 181\u001b[0m     success, message \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_impl()\n\u001b[0;32m    183\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m success:\n\u001b[0;32m    184\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfailed\u001b[39m\u001b[39m'\u001b[39m\n",
            "File \u001b[1;32mc:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\integrate\\_ivp\\rk.py:144\u001b[0m, in \u001b[0;36mRungeKutta._step_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    141\u001b[0m h \u001b[39m=\u001b[39m t_new \u001b[39m-\u001b[39m t\n\u001b[0;32m    142\u001b[0m h_abs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(h)\n\u001b[1;32m--> 144\u001b[0m y_new, f_new \u001b[39m=\u001b[39m rk_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun, t, y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf, h, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mA,\n\u001b[0;32m    145\u001b[0m                        \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mB, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mK)\n\u001b[0;32m    146\u001b[0m scale \u001b[39m=\u001b[39m atol \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mmaximum(np\u001b[39m.\u001b[39mabs(y), np\u001b[39m.\u001b[39mabs(y_new)) \u001b[39m*\u001b[39m rtol\n\u001b[0;32m    147\u001b[0m error_norm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_estimate_error_norm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK, h, scale)\n",
            "File \u001b[1;32mc:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\integrate\\_ivp\\rk.py:64\u001b[0m, in \u001b[0;36mrk_step\u001b[1;34m(fun, t, y, f, h, A, B, C, K)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m s, (a, c) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(A[\u001b[39m1\u001b[39m:], C[\u001b[39m1\u001b[39m:]), start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m     63\u001b[0m     dy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(K[:s]\u001b[39m.\u001b[39mT, a[:s]) \u001b[39m*\u001b[39m h\n\u001b[1;32m---> 64\u001b[0m     K[s] \u001b[39m=\u001b[39m fun(t \u001b[39m+\u001b[39;49m c \u001b[39m*\u001b[39;49m h, y \u001b[39m+\u001b[39;49m dy)\n\u001b[0;32m     66\u001b[0m y_new \u001b[39m=\u001b[39m y \u001b[39m+\u001b[39m h \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mdot(K[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mT, B)\n\u001b[0;32m     67\u001b[0m f_new \u001b[39m=\u001b[39m fun(t \u001b[39m+\u001b[39m h, y_new)\n",
            "File \u001b[1;32mc:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\integrate\\_ivp\\base.py:138\u001b[0m, in \u001b[0;36mOdeSolver.__init__.<locals>.fun\u001b[1;34m(t, y)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun\u001b[39m(t, y):\n\u001b[0;32m    137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun_single(t, y)\n",
            "File \u001b[1;32mc:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\scipy\\integrate\\_ivp\\base.py:20\u001b[0m, in \u001b[0;36mcheck_arguments.<locals>.fun_wrapped\u001b[1;34m(t, y)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfun_wrapped\u001b[39m(t, y):\n\u001b[1;32m---> 20\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(fun(t, y), dtype\u001b[39m=\u001b[39mdtype)\n",
            "File \u001b[1;32me:\\Metrized\\score_sde_pytorch\\likelihood.py:95\u001b[0m, in \u001b[0;36mget_likelihood_fn.<locals>.likelihood_fn.<locals>.ode_func\u001b[1;34m(t, x)\u001b[0m\n\u001b[0;32m     93\u001b[0m vec_t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(sample\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], device\u001b[39m=\u001b[39msample\u001b[39m.\u001b[39mdevice) \u001b[39m*\u001b[39m t\n\u001b[0;32m     94\u001b[0m drift \u001b[39m=\u001b[39m mutils\u001b[39m.\u001b[39mto_flattened_numpy(drift_fn(model, sample, vec_t))\n\u001b[1;32m---> 95\u001b[0m logp_grad \u001b[39m=\u001b[39m mutils\u001b[39m.\u001b[39;49mto_flattened_numpy(div_fn(model, sample, vec_t, epsilon))\n\u001b[0;32m     96\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mconcatenate([drift, logp_grad], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "File \u001b[1;32me:\\Metrized\\score_sde_pytorch\\models\\utils.py:183\u001b[0m, in \u001b[0;36mto_flattened_numpy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_flattened_numpy\u001b[39m(x):\n\u001b[0;32m    182\u001b[0m   \u001b[39m\"\"\"Flatten a torch tensor `x` and convert it to numpy.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m   \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,))\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title Likelihood computation\n",
        "train_ds, eval_ds, _ = datasets.get_dataset(config, uniform_dequantization=True, evaluation=True)\n",
        "eval_iter = iter(eval_ds)\n",
        "bpds = []\n",
        "likelihood_fn = likelihood.get_likelihood_fn(sde,                                              \n",
        "                                             inverse_scaler,                                             \n",
        "                                             eps=1e-5)\n",
        "\n",
        "counter = 0\n",
        "length = len(eval_ds) - 1\n",
        "for i, batch in enumerate(eval_iter):\n",
        "  img = batch['image']._numpy()\n",
        "  img = torch.tensor(img).permute(0, 3, 1, 2).to(config.device)\n",
        "  img = scaler(img)\n",
        "  bpd, z, nfe = likelihood_fn(score_model, img)\n",
        "  bpds.extend(bpd)\n",
        "  print(f\"batch: {i}/{length}, average bpd: {torch.tensor(bpds).mean().item()}, NFE: {nfe}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "oe3rLGRm28nc",
        "outputId": "4d3b614b-df5b-4523-aa91-a223d6134397"
      },
      "outputs": [],
      "source": [
        "#@title Representations\n",
        "train_ds, eval_ds, _ = datasets.get_dataset(config, uniform_dequantization=False, evaluation=True)\n",
        "eval_batch = next(iter(eval_ds))\n",
        "eval_images = eval_batch['image']._numpy()\n",
        "shape = (batch_size, 3, 32, 32)\n",
        "\n",
        "likelihood_fn = likelihood.get_likelihood_fn(sde, inverse_scaler, eps=1e-5)\n",
        "sampling_fn = sampling.get_ode_sampler(sde, shape, inverse_scaler,\n",
        "                                       denoise=True, eps=sampling_eps, device=config.device)\n",
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.axis('off')\n",
        "plt.imshow(image_grid(eval_images))\n",
        "plt.title('Original images')\n",
        "\n",
        "eval_images = torch.from_numpy(eval_images).permute(0, 3, 1, 2).to(config.device)\n",
        "_, latent_z, _ = likelihood_fn(score_model, scaler(eval_images))\n",
        "\n",
        "x, nfe = sampling_fn(score_model, latent_z)\n",
        "\n",
        "x = x.permute(0, 2, 3, 1).cpu().numpy()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.axis('off')\n",
        "plt.imshow(image_grid(x))\n",
        "plt.title('Reconstructed images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaGYVD7KcoW6"
      },
      "source": [
        "# Controllable generation\n",
        "\n",
        "Several demonstrations on how to solve inverse problems with our SDE framework.\n",
        "\n",
        "Recommended settings\n",
        "\n",
        "| dataset | SDE | predictor | corrector | snr | n_steps |\n",
        "|:----:|:----:|:----------:|:--------:|:---:|:----:|\n",
        "|CIFAR-10 | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.16| 1|\n",
        "|CIFAR-10 | VP | EulerMaruyamaPredictor | None | - | - |\n",
        "|CIFAR-10 | subVP| EulerMaruyamaPredictor | None | - | - |\n",
        "| LSUN/CelebA-HQ/FFHQ 256px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.075 | 1 |\n",
        "| FFHQ 1024px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.15| 1 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tbly_8RIjqJD",
        "outputId": "28ca290e-1079-4031-e37a-c69374398f76"
      },
      "outputs": [],
      "source": [
        "#@title PC inpainting\n",
        "train_ds, eval_ds, _ = datasets.get_dataset(config)\n",
        "eval_iter = iter(eval_ds)\n",
        "bpds = []\n",
        "\n",
        "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
        "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
        "snr = 0.16 #@param {\"type\": \"number\"}\n",
        "n_steps = 1 #@param {\"type\": \"integer\"}\n",
        "probability_flow = False #@param {\"type\": \"boolean\"}\n",
        "\n",
        "pc_inpainter = controllable_generation.get_pc_inpainter(sde,\n",
        "                                                        predictor, corrector,\n",
        "                                                        inverse_scaler,\n",
        "                                                        snr=snr,\n",
        "                                                        n_steps=n_steps,\n",
        "                                                        probability_flow=probability_flow,\n",
        "                                                        continuous=config.training.continuous,\n",
        "                                                        denoise=True)\n",
        "batch = next(eval_iter)\n",
        "img = batch['image']._numpy()\n",
        "img = torch.from_numpy(img).permute(0, 3, 1, 2).to(config.device)\n",
        "show_samples(img)\n",
        "\n",
        "mask = torch.ones_like(img)\n",
        "mask[:, :, :, 16:] = 0.\n",
        "show_samples(img * mask)\n",
        "\n",
        "\n",
        "x = pc_inpainter(score_model, scaler(img), mask)\n",
        "show_samples(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DsP-ayb8cupk",
        "outputId": "51272ecd-4ba3-4931-8a6d-358c6218e25b"
      },
      "outputs": [],
      "source": [
        "#@title PC colorizer\n",
        "train_ds, eval_ds, _ = datasets.get_dataset(config)\n",
        "eval_iter = iter(eval_ds)\n",
        "bpds = []\n",
        "\n",
        "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
        "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
        "snr = 0.16 #@param {\"type\": \"number\"}\n",
        "n_steps = 1 #@param {\"type\": \"integer\"}\n",
        "probability_flow = False #@param {\"type\": \"boolean\"}\n",
        "\n",
        "batch = next(eval_iter)\n",
        "img = batch['image']._numpy()\n",
        "img = torch.from_numpy(img).permute(0, 3, 1, 2).to(config.device)\n",
        "show_samples(img)\n",
        "gray_scale_img = torch.mean(img, dim=1, keepdims=True).repeat(1, 3, 1, 1)\n",
        "show_samples(gray_scale_img)\n",
        "gray_scale_img = scaler(gray_scale_img)\n",
        "pc_colorizer = controllable_generation.get_pc_colorizer(\n",
        "    sde, predictor, corrector, inverse_scaler,\n",
        "    snr=snr, n_steps=n_steps, probability_flow=probability_flow,\n",
        "    continuous=config.training.continuous, denoise=True\n",
        ")\n",
        "x = pc_colorizer(score_model, gray_scale_img)\n",
        "\n",
        "show_samples(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiYRNB-Wk329"
      },
      "source": [
        "## Class-conditional generation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTu-5e6S68Gb"
      },
      "source": [
        "Check out the [class-conditional generation section](https://colab.research.google.com/drive/1dRR_0gNRmfLtPavX2APzUggBuXyjWW55#scrollTo=HiYRNB-Wk329&line=3&uniqifier=1) in our [JAX demo](https://colab.research.google.com/drive/1dRR_0gNRmfLtPavX2APzUggBuXyjWW55?usp=sharing)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Score SDE demo PyTorch",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('pytorch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "739f515fbc693b0ef5b930780eef1a1b1825770e415178b662f8085df40d8af9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
